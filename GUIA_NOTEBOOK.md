# An√°lise de Probabilidades JDB ‚Äî Guia R√°pido

## üìã O que foi entregue

Um **notebook Jupyter completo e operacional** (`analise_probabilidades_operacional.ipynb`) que implementa um pipeline de an√°lise de probabilidades focado em:
- **Capacidade**: Dados reais (cache do pernambucoaval)
- **Clareza**: M√©tricas quantificadas e audit√°veis
- **Certeza**: Intervalos cred√≠veis, testes estat√≠sticos, calibra√ß√£o

---

## üîÑ Pipeline Implementado

### 1. **ETL ‚Äî Extra√ß√£o e Limpeza**
- Carrega `cache_results.json`
- Valida completude, duplicatas, range de grupos
- Retorna dataset limpo pronto para an√°lise

### 2. **An√°lise de Qualidade de Dados**
- **Distribui√ß√£o** por dezena (0‚Äì99), grupo (1‚Äì25), √∫ltimo d√≠gito
- **Teste Chi-square** de uniformidade (H0: distribui√ß√£o √© uniforme)
- **Coeficiente de varia√ß√£o** para detectar assimetrias
- **Q-Q plot** para normalidade

### 3. **Modelos Probabil√≠sticos**

#### a) **Poisson (Contagens)**
- Estima Œª (taxa de apari√ß√£o por dezena)
- Verifica overdispers√£o (Var/M√©dia)
- Identifica se modelo √© apropriado

#### b) **Bayesiano Hier√°rquico (Beta-Binomial)**
- Usa PyMC para amostrar posterior
- Implementa pooling parcial (regulariza√ß√£o)
- Gera intervalos cred√≠veis 95% por dezena/grupo
- Reduz vari√¢ncia comparado a MLE puro

#### c) **Intervalos de Confian√ßa (Clopper-Pearson)**
- M√©todo exato para propor√ß√µes binomiais
- Garante cobertura verdadeira (n√£o assint√≥tico)

### 4. **Calibra√ß√£o e M√©tricas de Certeza**
- **Brier Score**: erro quadr√°tico m√©dio (0 = perfeito)
- **Log-Loss**: penalidade de probabilidade
- **Reliability Diagram**: visual de calibra√ß√£o
- **Calibration Error (MAE)**

### 5. **Walk-Forward Backtest**
- Treina em 70% hist√≥rico, valida em 30%
- **Sem lookahead bias**: modelo usa apenas dados passados
- Computa **Mean Log-Likelihood** e **Perplexity** no test set

### 6. **VaR/CVaR ‚Äî Risco**
- Simula P&L de estrat√©gia (10.000 Monte Carlo, 100 rodadas)
- **VaR_95%**: pior cen√°rio 5%
- **CVaR_95%**: m√©dia das 5% piores perdas
- **Win Rate**: % de simula√ß√µes com lucro
- **Sharpe Ratio**: retorno/risco

### 7. **Relat√≥rio Final**
- Sum√°rio de dados, uniformidade, modelos, risco
- Recomenda√ß√µes acion√°veis
- Alertas cr√≠ticos
- Exporta em JSON

---

## üöÄ Como Usar

### Pr√©-requisitos
```bash
pip install pandas numpy matplotlib seaborn statsmodels scikit-learn scipy pymc
```

### Executar
1. Abra `analise_probabilidades_operacional.ipynb` no Jupyter
2. Execute c√©lula por c√©lula
3. Leia o relat√≥rio final (√∫ltima c√©lula)

Ou via terminal:
```bash
jupyter notebook analise_probabilidades_operacional.ipynb
```

---

## üìä Sa√≠das Esperadas

### Gr√°ficos
- Distribui√ß√£o por dezena, grupo, √∫ltimo d√≠gito
- Q-Q plot (normalidade)
- Reliability diagram (calibra√ß√£o)
- Histograma P&L (Monte Carlo)
- CDF do P&L com VaR

### Tabelas
- Estat√≠sticas de frequ√™ncia (min, max, m√©dia, CV)
- Intervalos de confian√ßa (top-5 dezenas)
- Summary posterior (Bayesiano)
- Walk-forward performance

### Relat√≥rio JSON
- `relatorio_analise_probabilidades.json`
  - Qualidade de dados
  - Testes de uniformidade
  - M√©tricas de modelos
  - Probabilidades posteriores (todas dezenas/grupos)
  - Risco (VaR, CVaR, Sharpe)

---

## üéØ Interpreta√ß√£o das M√©tricas

| M√©trica | Bom | Ruim | Interpreta√ß√£o |
|---------|-----|------|---------------|
| **p-value (Chi-square)** | > 0.05 | < 0.05 | Uniforme ‚úì vs. vi√©s detectado ‚ö† |
| **Brier Score** | < 0.15 | > 0.25 | Calibra√ß√£o boa vs. m√° |
| **Log-Loss** | < 0.69 | > 0.69 | Melhor que aleat√≥rio vs. pior |
| **Calibration Error** | < 0.05 | > 0.1 | Bem calibrado vs. descalibrado |
| **VaR_95%** | > 0 (lucro) | < 0 (perda) | Cen√°rio 5% √© ganho vs. perda |
| **Win Rate** | > 50% | < 50% | Mais ganhos vs. mais perdas |
| **Sharpe Ratio** | > 0 | < 0 | Retorno justifica risco vs. n√£o |

---

## ‚ö†Ô∏è Limita√ß√µes e Avisos

1. **Dados √∫nicos**: an√°lise baseada em 1 coleta (pernambucoaval). Para decis√µes, coletar hist√≥rico temporal.
2. **Per√≠odo**: amostra atual √© um "snapshot". Padr√µes podem variar no tempo.
3. **Modelo assume aleatoriedade**: Chi-square testa uniformidade. Se rejeitar, pode indicar:
   - Manipula√ß√£o
   - Vi√©s de coleta
   - Per√≠odo insuficiente
4. **Monte Carlo simplificado**: simula√ß√£o assume prob uniforme para pr√≥ximas rodadas (n√£o usa hist√≥rico).
5. **Estrat√©gia demo**: apostas em top-5 grupos √© exemplo. Otimizar com Kelly Criterion antes de usar.

---

## üîç Pr√≥ximos Passos Recomendados

1. **Hist√≥rico temporal**: coletar dados com timestamps (data/hora de cada sorteio)
2. **Modelos avan√ßados**:
   - AR(1) em logit para depend√™ncia temporal
   - HMM para detectar regimes (mudan√ßas estruturais)
   - Hawkes process se houve "clustering" de eventos
3. **Dados externos**: se dispon√≠vel, incorporar:
   - Padr√µes de apostas (se acesso)
   - Not√≠cias/eventos locais (NLP)
4. **Valida√ß√£o cont√≠nua**: reestimar modelo a cada nova coleta, acompanhar drift
5. **Otimiza√ß√£o**: usar Kelly Criterion para dimensionar stakes baseado em confian√ßa

---

## üìù Arquivos Gerados

- `analise_probabilidades_operacional.ipynb` ‚Äî Notebook completo
- `relatorio_analise_probabilidades.json` ‚Äî Sa√≠da estruturada (usa ap√≥s rodar notebook)

---

## üìû Suporte

Se modelos n√£o rodarem:
- Verificar PyMC instalado: `python -c "import pymc; print(pymc.__version__)"`
- Se amostragem lenta, reduzir `tune=1000` para `tune=500`
- Para dados grandes, considerar Stan em vez de PyMC

D√∫vidas sobre interpreta√ß√£o? Revisar se√ß√£o "Interpreta√ß√£o das M√©tricas" acima.

---

**Vers√£o**: 1.0  
**Data**: 3 de Dezembro de 2025  
**Status**: Pronto para uso operacional
