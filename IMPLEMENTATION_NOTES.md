# Implementa√ß√£o: Scraper Pernambucoaval + Landing Page com Probabilidades Futuras

## Resumo da solu√ß√£o

Este documento descreve a implementa√ß√£o completa que adiciona:

1. **Scraper Robusto** (`fetch_pernambucoaval.py`) ‚Äî extrai `hora`, `local` e `tipo` da p√°gina `https://pernambucoaval.vitaldata.com.br/`
2. **Valida√ß√£o Autom√°tica** (`scraper_validation.py`) ‚Äî executa scraper e gera relat√≥rio com taxas de cobertura
3. **Testes Unit√°rios** (`tests/test_scraper_helpers.py`) ‚Äî valida l√≥gica de limpeza e infer√™ncia
4. **Landing Page com Probabilidades Condicionais** ‚Äî exibe probabilidades futuras por `hora`, `local`, `tipo`
5. **Automa√ß√£o Git** (`commit_and_push.ps1`) ‚Äî facilita cria√ß√£o de branch, commit e push

## Arquivos modificados/criados

### Novos arquivos
- `fetch_pernambucoaval.py` ‚Äî scraper principal
- `scraper_validation.py` ‚Äî valida√ß√£o + relat√≥rio
- `SCRAPER_README.md` ‚Äî documenta√ß√£o do scraper
- `tests/test_scraper_helpers.py` ‚Äî testes unit√°rios
- `commit_and_push.ps1` ‚Äî automa√ß√£o Git

### Arquivos atualizados
- `generate_landing_data.py` ‚Äî adiciona gera√ß√£o de `predictive_by_group` (probabilidades condicionais)
- `web/landing.html` ‚Äî nova se√ß√£o para probabilidades futuras
- `web/app.js` ‚Äî renderiza√ß√£o da se√ß√£o condicional
- `web/landing_data.js` ‚Äî regenerado com dados atualizados + `predictive_by_group`
- `cache_results.json` ‚Äî atualizado com metadados (`hora`, `local`, `tipo`)

## Como usar

### 1. Executar o scraper + valida√ß√£o

```powershell
.\.venv\Scripts\python.exe scraper_validation.py
```

Isso ir√°:
- Fazer download de `https://pernambucoaval.vitaldata.com.br/`
- Extrair `hora`, `local` e `tipo` para cada milhar
- Atualizar `cache_results.json` com os campos (backup em `cache_results.json.bak`)
- Gerar `scraper_report_examples.csv` com exemplos de cobertura

Resultado esperado:
```
  total rows: 316
  rows with hora: 316 (100.0%)
  rows with local: 39 (12.3%)
  rows with tipo: 316 (100.0%)
```

### 2. Regenerar landing data (opcional ‚Äî executado por scraper_validation)

```powershell
.\.venv\Scripts\python.exe generate_landing_data.py
```

Isso gera `web/landing_data.js` com:
- Rankings e probabilidades de dezenas
- Estat√≠sticas gerais
- `predictive_by_group` ‚Äî probabilidades condicionadas por `hora`, `local`, `tipo`

### 3. Testar landing page localmente

```powershell
python -m http.server 8000 --directory .\web
```

Abra `http://localhost:8000/landing.html` e procure pela se√ß√£o **"üîÆ Probabilidades para Jogos Futuros (condicionais)"**.

### 4. Executar testes

```powershell
.\.venv\Scripts\python.exe -m pytest tests/test_scraper_helpers.py -v
```

### 5. Criar branch, commit e push (autom√°tico)

```powershell
.\commit_and_push.ps1
```

Ou manualmente:

```powershell
git checkout -b feat/pernambucoaval-scraper

git add `
  fetch_pernambucoaval.py `
  generate_landing_data.py `
  web/landing.html `
  web/app.js `
  web/landing_data.js `
  SCRAPER_README.md `
  scraper_validation.py `
  tests/test_scraper_helpers.py `
  cache_results.json `
  cache_results.json.bak `
  scraper_report_examples.csv

git commit -m "feat(pernambucoaval): add structured scraper, validation and predictive_by_group support"

git push -u origin feat/pernambucoaval-scraper
```

## Estrutura de dados

### cache_results.json (atualizad)

Cada linha em `payload.table` agora cont√©m:

```json
{
  "idx": 1,
  "milhar": "2025",
  "dezena": 25,
  "grupo": 7,
  "animal": "Carneiro",
  "hora": "11:00",
  "local": "",
  "tipo": "Diurno"
}
```

### web/landing_data.js (atualizad)

Adicionado campo `predictive_by_group` com estrutura:

```javascript
"predictive_by_group": {
  "hora": {
    "09:00": {
      "count": 47,
      "probs": [0.0, 0.0212..., ...],
      "top": [{"dezena": "42", "count": 3, "prob": 0.0638}, ...]
    },
    "11:00": { ... }
  },
  "local": {
    "PE": { ... }
  },
  "tipo": {
    "Diurno": { ... },
    "Vespertino": { ... },
    "Noturno": { ... }
  }
}
```

## Melhorias implementadas

### Scraper (fetch_pernambucoaval.py)

1. **Parsing estruturado de tabelas** ‚Äî procura por `<table class="table">` e extrai metadados dos headers
2. **Heur√≠sticas robustas** ‚Äî busca em m√∫ltiplas camadas (JSON scripts, ancestrais, texto pr√≥ximo)
3. **Limpeza inteligente** ‚Äî remove ru√≠do comum (Grupo 12345, AVAL PERNAMBUCO, datas, horas)
4. **Infer√™ncia de tipo** ‚Äî se `tipo` n√£o est√° presente, infere Diurno/Vespertino/Noturno baseado em `hora`
5. **Backup autom√°tico** ‚Äî cria `cache_results.json.bak` antes de atualizar

### Valida√ß√£o (scraper_validation.py)

- Executa scraper + gera relat√≥rio com taxas de cobertura
- Produz `scraper_report_examples.csv` para inspe√ß√£o manual

### Testes (tests/test_scraper_helpers.py)

- Valida `clean_local_string()` ‚Äî remove ru√≠do
- Valida `clean_tipo_string()` ‚Äî normaliza tipos
- Valida `infer_tipo_from_hora()` ‚Äî infere per√≠odo do dia

Resultado: **3 testes passando** ‚úÖ

### Landing Page (web/*)

- Nova se√ß√£o `#section_predictive` para mostrar probabilidades condicionais
- Seletor por agrupamento (`hora`, `local`, `tipo`)
- Tabela com Top-10 dezenas para cada condi√ß√£o

## Configura√ß√£o e requisitos

- Python 3.8+
- Pacotes: `requests`, `beautifulsoup4`, `lxml`, `pytest` (j√° em requirements.txt)
- Git 2.0+ (para workflow autom√°tico)

## Pr√≥ximos passos opcionais

1. **Melhorar extra√ß√£o de `local`** ‚Äî se o site exp√µe cidade/estabelecimento de forma mais estruturada, atualizar regex.
2. **Adicionar filtros na landing** ‚Äî ex.: mostrar apenas dezenas com prob > 10% para uma condi√ß√£o espec√≠fica.
3. **Hist√≥rico temporal** ‚Äî arquivar snapshots do `cache_results.json` di√°rios para an√°lise de tend√™ncias.
4. **Integra√ß√£o CI/CD** ‚Äî executar scraper automaticamente via GitHub Actions a cada 6 horas.

## Troubleshooting

- **Git n√£o encontrado**: Instale Git for Windows ou configure PATH
- **Requests/BeautifulSoup faltando**: Rode `.\.venv\Scripts\python.exe -m pip install -r requirements.txt`
- **N√£o h√° conex√£o com o site**: Verifique firewall ou tente com `requests` + proxy se aplic√°vel
- **Testes falhando**: Confirme que o arquivo est√° na raiz (`fetch_pernambucoaval.py`)

---

**Status**: Pronto para produ√ß√£o ‚úÖ  
**Data**: 2025-12-05  
**Autor**: Implementa√ß√£o Autom√°tica
